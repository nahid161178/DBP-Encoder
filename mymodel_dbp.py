# -*- coding: utf-8 -*-
"""myModel_DBP.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1BdVxQqJpQ_KnPa1rpJUA9KnqOf2avu-U
"""

from google.colab import drive
drive.mount("/content/drive/")

"""Instructions for Google colab:
1.If you use colab,you can run the model without any changing.
2.You need datasets from our given Github Link : https://github.com/nahid161178/DBPa-AutoEncoder
Just extract the csv file,upload it on colab and run the code to use the model.

Instructions for Jupyter Notebook:
1.You need datasets from our given Github Link : https://github.com/nahid161178/DBPa-AutoEncoder
2.Just download this colab coded file in your machine and also download the extracted datasets from above Git Hub link.
3.Run the model

## **Best Wishes!!!!!!!**

## **Import required Libraries for experiment**
"""

import keras
import numpy as np
import pandas as pd
import math
import gc
from itertools import *
import matplotlib as plt
from sklearn.metrics import roc_curve, roc_auc_score

import matplotlib.pyplot as plt

from keras import backend as K
from keras.models import Model, Input
from keras.layers.merge import concatenate
from keras.optimizers import Adam
from keras.utils import to_categorical
from sklearn.model_selection import KFold
from sklearn.metrics import confusion_matrix, accuracy_score, matthews_corrcoef, precision_score, roc_auc_score
from sklearn.metrics import accuracy_score
from sklearn import metrics
from sklearn.model_selection import cross_val_score
from sklearn.metrics import recall_score
from sklearn.metrics import roc_auc_score
from sklearn.metrics import matthews_corrcoef
from sklearn.metrics import average_precision_score
from sklearn.metrics import roc_curve
from sklearn.model_selection import KFold

from sklearn import svm

from keras.models import Sequential
from keras.layers import Dense
from keras.layers import Dropout
#from sklearn.metrics import plot_roc_curve



"""## **Load extracted datasets F1,F2,F3,F4 as CSV both Train and Test**"""

df = pd.read_csv('/content/train_C_normalized_gap.csv',low_memory=False)
trainC_data = np.asarray(df.iloc[:, 1:-1])
trainC_target = np.asarray(df.iloc[:,-1])
trainC_feature_name = list(df.columns.values[:-1])


df = pd.read_csv('/content/train_E_normalized_monogram.csv',low_memory=False)
trainE_data = np.asarray(df.iloc[:, 1:-1])
trainE_target = np.asarray(df.iloc[:,-1])
trainE_feature_name = list(df.columns.values[:-1])


df = pd.read_csv('/content/train_F_normalized_bigram.csv',low_memory=False)
trainF_data = np.asarray(df.iloc[:, 1:-1])
trainF_target = np.asarray(df.iloc[:,-1])
trainF_feature_name = list(df.columns.values[:-1])


df = pd.read_csv('/content/train_G_normalized_nearest_neigbour.csv',low_memory=False)
trainG_data = np.asarray(df.iloc[:, 1:-1])
trainG_target = np.asarray(df.iloc[:,-1])
trainG_feature_name = list(df.columns.values[:-1])

df = pd.read_csv('/content/test_C_normalized_gap.csv',low_memory=False)
testC_data = np.asarray(df.iloc[:, 1:-1])
testC_target = np.asarray(df.iloc[:,-1])
testC_feature_name = list(df.columns.values[:-1])

df = pd.read_csv('/content/test_E_normalized_monogram.csv',low_memory=False)
testE_data = np.asarray(df.iloc[:, 1:-1])
testE_target = np.asarray(df.iloc[:,-1])
testE_feature_name = list(df.columns.values[:-1])

df = pd.read_csv('/content/test_F_normalized_bigram.csv',low_memory=False)
testF_data = np.asarray(df.iloc[:, 1:-1])
testF_target = np.asarray(df.iloc[:,-1])
testF_feature_name = list(df.columns.values[:-1])

df = pd.read_csv('/content/test_G_normalized_nearest_neigbour.csv',low_memory=False)
testG_data = np.asarray(df.iloc[:, 1:-1])
testG_target = np.asarray(df.iloc[:,-1])
testG_feature_name = list(df.columns.values[:-1])

train_target = trainC_target
test_target = testC_target

"""### **Train Four Separated Shallow Neural Networks for F1,F2,F3,F4 and Reconstruct F1 --> EF1 , F2 -- > EF2 , F3 --> EF3 , F4 -->EF4**"""

model = Sequential()
model.add(Dense(128, input_dim=8000, activation='relu'))
#model.add(Dropout(0.2))
model.add(Dense(64, activation='relu'))
#model.add(Dropout(0.2))
model.add(Dense(32, activation='relu',name ='my_layer'))
model.add(Dense(1, activation='sigmoid'))

model.compile(loss='binary_crossentropy', optimizer='RMSprop', metrics=['accuracy'])
model.fit(trainC_data,train_target, epochs=10)

layerIndex = 2
func = K.function([model.get_layer(index=0).input], model.get_layer(index=layerIndex).output)
layerOutput_train1 = func([trainC_data])
newC_train = layerOutput_train1
layerOutput_test1 = func([testC_data])
newC_test = layerOutput_test1

model = Sequential()
model.add(Dense(128, input_dim=200, activation='relu'))
#model.add(Dropout(0.2))
model.add(Dense(64, activation='relu'))
#model.add(Dropout(0.2))
model.add(Dense(32, activation='relu',name ='my_layer'))
model.add(Dense(1, activation='sigmoid'))

model.compile(loss='binary_crossentropy', optimizer='RMSprop', metrics=['accuracy'])
model.fit(trainE_data,train_target, epochs=150)

layerIndex = 2
func = K.function([model.get_layer(index=0).input], model.get_layer(index=layerIndex).output)
layerOutput_train2 = func([trainE_data])
newE_train = layerOutput_train2
layerOutput_test2 = func([testE_data])
newE_test = layerOutput_test2

model = Sequential()
model.add(Dense(128, input_dim=4000, activation='relu'))
#model.add(Dropout(0.2))
model.add(Dense(64, activation='relu'))
#model.add(Dropout(0.2))
model.add(Dense(32, activation='relu',name ='my_layer'))
model.add(Dense(1, activation='sigmoid'))

model.compile(loss='binary_crossentropy', optimizer='RMSprop', metrics=['accuracy'])
model.fit(trainF_data,train_target, epochs=10)

layerIndex = 2
func = K.function([model.get_layer(index=0).input], model.get_layer(index=layerIndex).output)
layerOutput_train3 = func([trainF_data])
newF_train = layerOutput_train3
layerOutput_test3 = func([testF_data])
newF_test = layerOutput_test3

model = Sequential()
model.add(Dense(128, input_dim=12000, activation='relu'))
#model.add(Dropout(0.2))
model.add(Dense(64, activation='relu'))
#model.add(Dropout(0.2))
model.add(Dense(32, activation='relu',name ='my_layer'))
model.add(Dense(1, activation='sigmoid'))

model.compile(loss='binary_crossentropy', optimizer='RMSprop', metrics=['accuracy'])
model.fit(trainG_data,train_target, epochs=20)

layerIndex = 2
func = K.function([model.get_layer(index=0).input], model.get_layer(index=layerIndex).output)
layerOutput_train4 = func([trainG_data])
newG_train = layerOutput_train4
layerOutput_test4 = func([testG_data])
newG_test = layerOutput_test4

"""## **Merge EF1,EF2,EF3 encoded features**"""

CF_train = np.hstack((newC_train,newF_train))
CF_test =  np.hstack((newC_test,newF_test))

CFG_train = np.hstack((CF_train,newG_train))
CFG_test =  np.hstack((CF_test,newG_test))

"""## **Train a Support Vector Machine on EF1 + EF2 + EF3 and Output the Test results**"""

sv1=svm.SVC(kernel='rbf',gamma = 8 ,probability=True)
sv1.fit(CFG_train, train_target)
test_sv = sv1.predict(CFG_test)
test_proba = sv1.predict_proba(CFG_test)
y_test_score = sv1.decision_function(CFG_test)
test_acc_score_sv =accuracy_score(test_target, test_sv)
test_recall_score_sv = recall_score(test_target, test_sv) #sensitivtiy
test_specificity_sv = (2*test_acc_score_sv) - test_recall_score_sv #specificity or confusion matrix
test_auroc_score_sv = roc_auc_score(test_target, test_sv)
test_auPR_score_sv = average_precision_score(test_target, test_sv)
test_mcc_score_sv = matthews_corrcoef(test_target, test_sv)

print ("myModel = DBP_Encoder result analysis : Accuracy, Sn, Sp, AuROC, AuPR ,MCC --> ")
print("{0:3.6},{1:3.6},{2:3.6},{3:3.6},{4:3.6},{5:3.6}\n".format(test_acc_score_sv*100, np.mean(test_recall_score_sv), np.mean(test_specificity_sv), test_auroc_score_sv, test_auPR_score_sv,test_mcc_score_sv))

"""## **ROC curve analysis**"""

r_probs = [0 for _ in range(len(test_target))]
nb_probs = test_proba[:, 1]

r_auc = roc_auc_score(test_target, r_probs)
nb_auc = roc_auc_score(test_target, nb_probs)

r_fpr, r_tpr, _ = roc_curve(test_target, r_probs)
nb_fpr, nb_tpr, _ = roc_curve(test_target,y_test_score)

plt.plot(r_fpr, r_tpr, linestyle='--', label='randomModel')
plt.plot(nb_fpr, nb_tpr, marker='.', label='myModel')
plt.title('ROC Plot')

plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.legend() 
plt.show()









